j=0
j=j+1
txt=["TTCGGCTTTA GAACCATTGG TAGATTCGCC AACAGGTATT AACATCACTA GGTTTCAAAC TTTACTTGCT TCACATAGAA GTTATTTGAC TCCTGGTGAT TCTTCTTCAG GTTAGACAGC TGGTGCTGTA GCTTATTATG TGGGTTATCT TCAACCTAGG ATTTCTCTAT TAAAATATAA TGAAAATGGA ATCACTACAG ATGCTGTAGG CTGTGCACTT GACCCTCTCT CAGAAATAAA GTGTACGTTG AAATCCTGCA CTGCAGGAAG AGGAACCTAT CAAACTTTTA ACTTTAGAGT CCAACCAATA GAATCTATTG TTAGATTTCC TAATATTACA AACTTGTGCC CTTTTGGTGA AGCTTTTAAC GCCATCAGAT TTGCATCTGT TTATGCTTGG AACAAGAAGA GAATCAGCAA CTCTGTTGCT GATTATTTTG TCCTATATAA TTTCGTATCA TTTTCCATTT TTAAGTTTTA TGGAGCGTCT CCTACTAAAT TAAATGATCT CTGCTTTACT AATGTCTATG CAGATTTATC TGCAACTAGA GGTGATGAAG TCAGACCAAC CGCTCCAGGG CAAACTGGAA AGATTGTTGA TTATAATTGT AAATTACAAG GTGATTTTAT AGACTGCGTT ATAGCTTAGA ATTCTAA"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["TTTGGGTTTA GGACGATAGG TAGGTTTGCA AACAGGTATT AACACCATTA GGTTTCTAAT TTTACTTGCT TTACATAGAA ATTATTTGAC TCCTGGTGAT TCTTCTTCAG ATTGGATAGC TGGTGCTGTA GCTTATTATG TGGGTTGTCT TCCACCTAGG ATTTTTCAAT TAAAATATAA TGAAAGTGGA ACCATTACAG GTGCTGTAGA CTGTGCACTT GACCCTCCCT CAGGAACAAA GTGTACGTTG AAATCCTTCA TTGCAGAAAA AGGAACCTAT CAAACTTCTA ACTCTAGAGT CCAACTAACA GAATCTATTG CTAGATTTCC TAATATTACA AACTTGTGCC CTTCTGGTGA AGTTTTTAAC GGCACCAGAT TTGCATCTGT TTGTGCTTGG AACAAGAAGA GAATCAGCAG CTGTGTTGCT GATTATTCTG TCCCATATAA TTCCGCATCA TTTTTCACTT TTAAGTGTTG TGGAGCGTCT CCTACTAAAT TAAATGATCT CTGCTATATT AATGTCTTTG CAGATTCATA TGCAATTAGA GGTGATGAAG CCAAACGAAT CGCTCCAGAG CAAACTGGAA GGATTGCTGA TTATAATTAT AAATTACCAG GTGATTCTAC AGACTGCGTT ATAGCTTGGA ATTTTAA"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["TTCGGCTTTA GAACCATTGG TAGATTTGCC AATAGGTATT AACACCACTA GGTTTCAAAC TTCACCTGCT TTACATAGAA GTTATTCGAT TCCTGGTGAT TCTTCTTCAG ATTGGACAGT TGGTGCTGTA GTTTATTGTG CGGCTTGTCC TCGACCTAGG ACTTTTCCAT TAAAATATAA TGAAAGTGGA ACCATTACAG ATGTTGTAGA CTGTGTACAT GACCCTCACT CAGAAATAAA GTGTATGTGG AGATCCTTCA CTGCAGAAAA AGGAACCTGT CAAATTTCTA ACTTTAGAGC CCAACCAACA GAATCTATTG CTAGATTTCC TAATATTACA AGCTTGTGCC ATTTTGGTGA AGCTTTTAAC GCCACCAGAT TTGCATCTGT TTATGCTTAG AGCAGGAGGA GAATCAGCAA CTGTGTTGCT GATTATTCTG TCCAATATAA TTCCGCATTA TTTTTCACTT TTAAGTCTTA TGGAGTGTCT CCTACTAAAT TAAATGATCT CTGCTTTACT AATGCCTATG CAGATTCATT TGCAATTAGA GATGATGAAG TCAAACTAAC CGCTCCAGGG CAAATTGGAA AGATTGCTGA TTGTAATTAT AAATCACCAG ATGATTTTAC AGACTGCGAT ATAGCTTGGA ATTCTAA"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["TTCGGCTTTA GAACCATCGG AAGATTTGCC AATAGGTATT AACACCACTA GGTTTCAAAC TTTACTTGTT TCACATAGAA GTTATTCGAC TCCTGGTGAT TCTTCTTCAG ATTAGATAGC TGGTGTTGTA GCTTATTATG TGGGTTATCT TCGACCTAGG ACTTTTCTAT TAAAATATAA TGAAAGTGGA ACCATTATAG ATGTTGCAGG CTGTGTACAT GACCTTCTCT CAGAAACAAA GTGTATGTAG AAATCCTTCA CTGTAGAAAG AGAAATCTAT CTAACTTCTA ACTTTAGAGC CCAACCAACA GAATCTACTG TTAGATTTCC TAATACTACA AACTTGTGCC GTTTTGGTGA AGTTTCTAAC GCCATCAGAT ATGTATCTGT TTGTGCTTGG AACAGGAGGA AAATCAGCAA CTTTGCTGCT GATTGTTCTG CCCCATATAA TTTCGCATCA TTTTCCACTT TTAAGTCTTA TGGAGTGTAT CCTACTAAAT TAAATGATCT CTGCTATATT AATGTCTTTG TAGGTTCATT TGTAATTAGA GATGATGAAG TCAGACTAAT CGGTCCAGGG CTAACTGGAA AGATTGTTGA TTATAATTGT AAATTACTAG ATGATTTTAC AGGCTGCGTT ACAGCTTAGA GTTTTAA"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["TTCGGATTCA GGACTATAGG GAGATTTGCC AACAGGTACT AACACCATTA GGTTTCGAAC TTTACTTGCT TTACGTAGAA GTTGTTTGAC TCGTGGTGAT TCTTTTTTAG ATTGGACAGC TGGTGCTGTA GCTTATTGTG TGGGTTGTCT TCCACATAGG ATTTCTCTAT AAAGATCTAA TGAAAGTGGA ATCATTACAG GTGCTGTAGA CTCTGCACTT GACCCTCGCT GAGAAATAAA GTGTACGTGG AGATACTACA CTGTAGAAAA AGAAATCTCT CAAATTTTTA ACTTTAGAGC CCCACAAATA GGATCTATTG TTAGATTTCA TAATACTACA AACTTGTCCC CTTCTGGTGA AGCTTTTAAC GCCATCAAAT ATGCATCTGC TTGTGCTTAG AGCAAGAGGA GAACCAGCAA CTGTGCTGTT GATTATTTTG TCCTATATAA TTTCGCATCA TTTTCCATTT CTAAGTGTTA TGGAGCGTCT CGTACTAAAT CAAGTGATCT CTCCTTTATT AATGCCTTTG CAGGTTCATC TGTAATTAGA GATGATGAAG CCAGACGAAT CGGTCCAGAG CAAATTGGAA AGATTGTTGA TTATAATTGT AAATAACCAG ATGATTTTAT AGACTGCGAT ACAGTTTAGA GTTTTAA"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["TGTGATGTTG TAATCGGAAT CGTGAATAAC ACAGTATATG ACCCCTTACA GCCTGAATTA GACTCATTTA AAGAAGAGTT GGACAAGTAC TTTAAAAATC ACACAT "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["ACCCGTTCCA TGTGGTCATT CAATCCAGAA ACTAACATTC TTCTCAACGT ACCACTGCAT GGCACTATAC TGACAAGACC ACTTCTAGAA AGTGAGCTCG TAATCGGTGC TGTGATACTT CGTGGACACC TTCGTATAGC TGGACATCAC CTAGGACGCT GTGATATAAA AGATCTGCCA AAA "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["CTGTTGCTCC ACCACGAACG GTTTCTTATT ACAAACTGGG AACTTCGAAG TGTGTAGCAA GTGACGCAAG TTTTGCTTCA TACAGTCGCT ACAGGCTTGG CTACTATAAA CTAAACTCAG ACAATTCCAG TTGCAGTCAC AATCTTACTT TGCTTGTACA GTAAGTGACA GCAAATGTTT CACCTCGTCG ACTTCCAGGT CACTATAGCA GAGATATTAC TTATAATAAT GAGGACTTTC AAAGTTTCGA TCTGGAATCT AGACTATATC ATAAATCTCA TTATCAAGAA CTTGTCTAAA TCACTGACTG AAAATAAGTA TTCCCAATTG GATGAGGAAC AACCGATGGA GATTGACTAA "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["CAACCAACAG AATCAATTGT TAGATTTCCT AATATAACAA ACTTGTGCCC TTTTGGCGAA GTTTTTAACG CCACCAGATT TGCATCTGTT TATGCTTGGA ATAGGAAGAG AATCAGCAAC TGTGTGGCTG ACTATTCGGT ACTATATAAC TCCGCATCAT TTTCCACTTT TAAGTGTTAC GGAGTGTCGC CTACTAAATT AAACGATCTT TGCTTTACTA ATGTCTATGC AGACTCATTT GTAATTAGAG GTGACGAAGT GAGGCAAATC GCGCCAGGGC AAACGGGCAA TATTGCTGAT TATAATTATA AATTACCAGA TGATTTTACA GGCTGCGTGA TAGCTTGGAA TTCTAACAAT CTTGATTCTA AGGTTGGTGG TAATTATAAT TACCTGTATA GATTGTTTAG GAAGTCTAAT CTCAAACCTT TTGAGAGAGA TATTTCAACG GAAATCTACC AGGCCGGTAG TACACCTTGT AATGGTGTTA AAGGTTTTAA TTGTTACTTT CCTTTACAGT CATATGGATT CCAACCTACC TACGGTGTTG GTTACCAACC TTACAGAGTA GTAGTACTTT CTTTTGAGCT ACTACATGCA CCAGCAACTG TTTGTGGACC TAAAAAGTCT ACTAATTTGG TTAAGAACAA ATGCGTCAAC TTTAAT "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["CAACCAACAG AATCTATTGT TAGATTTCCC AATATAACGA ATTTGTGTCC TTTCGGAGAA GTTTTTAACG CCACCAGATT TGCATCCGTT TATGCTTGGA ACAGAAAGAG GATTAGCAAT TGCGTTGCTG ATTATTCGGT ACTATACAAC TCTGCATCAT TCTCCACTTT TAAGTGTTAT GGAGTGTCTC CTACTAAATT AAATGATCTC TGCTTTACTA ATGTCTATGC AGATTCATTT GTTATTAGAG GAGACGAAGT CAGGCAAATA GCTCCAGGGC AGACGGGAAA TATTGCTGAT TATAATTATA AATTACCAGA TGATTTTACA GGCTGTGTTA TAGCTTGGAA TTCTAACAAT CTTGATTCTA AGGTTGGTGG CAACTACAAT TACCTATACA GATTGTTTAG AAAGTCTAAT CTCAAACCGT TTGAAAGGGA TATTTCAACT GAAATCTATC AAGCCGGAAG CACACCTTGT AATGGTGTTA AAGGTTTTAA TTGCTACTTC CCTTTACAAT CATACGGTTT CCAACCTACT TACGGTGTTG GTTACCAACC ATATAGAGTA GTCGTGCTTT CTTTCGAACT TCTACATGCA CCAGCAACGG TTTGTGGACC AAAAAAATCT ACTAACTTAG TTAAAAATAA GTGCGTCAAC TTTAAC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["CAACCGACAG AATCTATTGT TAGATTTCCT AATATTACAA ACTTGTGCCC TTTTGGTGAA GTTTTTAACG CCACCAGATT TGCATCTGTT TATGCCTGGA ACAGAAAAAG GATCAGCAAC TGTGTGGCTG ATTATTCTGT CCTATACAAT TCTGCATCAT TTTCCACTTT CAAGTGCTAT GGAGTGTCTC CAACTAAATT GAATGATCTC TGTTTTACGA ACGTCTATGC AGATTCATTT GTAATTAGAG GCGACGAGGT CAGACAAATT GCTCCAGGCC AAACTGGCAA TATTGCCGAT TATAATTATA AATTGCCAGA TGATTTTACT GGCTGCGTTA TTGCTTGGAA CTCTAATAAC CTTGATTCTA AGGTAGGTGG TAATTATAAT TACCTGTATA GGTTGTTTAG AAAGTCTAAT CTCAAACCTT TTGAGAGAGA TATTTCCACA GAAATCTATC AAGCCGGTAG CACACCATGT AATGGTGTTA AAGGTTTCAA TTGTTACTTT CCTTTACAGT CTTACGGCTT CCAACCCACC TATGGGGTGG GTTACCAGCC ATACAGAGTG GTTGTACTTT CTTTTGAGCT TCTACACGCG CCAGCAACGG TTTGTGGGCC TAAAAAATCT ACTAATTTGG TTAAGAATAA GTGTGTCAAT TTCAAC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["CAGCCGACCG AGTCTATAGT TAGGTTCCCT AATATAACAA ATTTGTGCCC TTTCGGAGAA GTTTTCAATG CGACCAGGTT CGCATCTGTG TACGCTTGGA ATAGGAAAAG GATTAGCAAC TGCGTTGCTG ATTATTCAGT CCTATATAAC TCAGCCTCAT TCTCCACTTT TAAGTGTTAT GGAGTGTCTC CTACTAAATT GAATGACCTA TGCTTTACTA ATGTGTATGC AGACTCGTTC GTAATTAGAG GTGACGAAGT CAGACAAATC GCTCCTGGGC AAACTGGCAA CATAGCTGAC TACAATTACA AATTGCCCGA TGATTTCACA GGCTGCGTCA TCGCGTGGAA CTCAAACAAC CTTGACTCTA AGGTAGGTGG TAATTATAAT TATCTCTATA GGTTATTCAG GAAGTCGAAC CTCAAACCGT TTGAAAGAGA CATCTCAACT GAAATCTACC AGGCCGGCAG TACTCCTTGT AATGGCGTTA AAGGTTTCAA TTGTTATTTC CCTTTACAGT CATACGGTTT TCAACCCACT TATGGTGTCG GTTATCAGCC ATACAGAGTA GTAGTACTTT CGTTTGAACT GCTCCATGCG CCAGCAACTG TTTGCGGACC GAAGAAGTCT ACGAACTTAG TTAAAAACAA ATGCGTCAAT TTCAAC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["CAACCAACAG AATCTATTGT TAGATTCCCT AACATTACAA ATTTGTGTCC TTTTGGTGAA GTTTTTAACG CCACCAGATT TGCATCCGTT TATGCTTGGA ACAGGAAGAG AATCAGCAAC TGCGTTGCTG ATTATTCTGT CCTATATAAT TCCGCATCAT TTTCCACTTT TAAGTGTTAT GGAGTGTCTC CTACTAAATT AAATGATCTT TGCTTTACTA ATGTCTATGC AGATTCATTT GTAATTAGAG GTGATGAGGT CAGACAAATC GCTCCAGGGC AAACTGGAAA TATTGCTGAT TATAATTATA AATTACCAGA TGATTTTACA GGCTGCGTTA TAGCTTGGAA TTCTAACAAT CTTGATTCCA AGGTTGGTGG TAATTATAAT TATCTGTATA GGTTGTTTAG GAAGTCTAAT CTTAAACCTT TCGAGAGAGA TATTTCAACT GAAATCTATC AAGCCGGTAG CACACCATGT AATGGTGTTA AAGGTTTTAA TTGTTACTTT CCTTTACAAT CATATGGTTT CCAACCCACT TATGGTGTTG GTTACCAACC ATACAGAGTA GTAGTACTTT CTTTTGAACT TCTGCATGCA CCAGCAACTG TTTGTGGTCC TAAAAAGTCA ACTAATTTGG TTAAAAACAA ATGTGTCAAT TTCAAC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["TTCAATGGTT TGACAGGCAC AGGTGTTCTC ACTGAGTCTA ACAAAAAGTT TCTGCCTTTC CAACAATTTG GCAGAGACAT AGCTGATACT ACAGATGCAG TCCGCGATCC TCAAACACTT GAGATTCTTG ACATTACTCC ATGTTCTTTT GGTGGTGTCA GCGTTATAAC ACCAGGAACA AATACTTCCA ACCAGGTCGC TGTTCTTTAT CAGGGTGTCA ACTGTACAGA AGTGCCTGTT GCTATTCACG CAGATCAACT TACCCCTACT TGGCGTGTTT ATTCTACAGG TTCTAATGTT TTTCAAACAC GTGCAGGCTG TTTAATAGGC GCTGAACATG TTAACAACTC ATATGAGTGT GACATACCTA TTGGTGCAGG TATATGCGCC AGTTATCAAA CTCAGACTAA TTCTCCTCGT CGTGCACGTA GTGTAGCTAG TCAATCCATC ATTGCCTACA CTATGTCACT TGGTGTAGAA AATTCAGTTG CTTACTCTAA TAACTCTATT GCCATACCCA CAAATTTTAC TATTAGTGTT ACCACAGAAA TTCTACCAGT GTCTATGACC AAGACATCAG TAGATTGTAC AATGTACATT TGCGGTGATT CAACTGAATG CAGCAATCTT TTGTTGCAGT ATGGCAGTTT TTGCACACAG TTAAACCGTG CTTTAACTGG AATCGCTGTT GAACAAGATA AAAACACCCA AGAAGTTTTT GCACAGGTCA AACAGATTTA C "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AAGGTCGAGG CTGAAGTGCA AATTGATAGG TTAATTACCG GCAGACTTCA AAGTTTGCAG ACATATGTGA CTCAACAATT AATTAGAGCT GCAGAAATCA GAGCTTCTGC GAATCTTGCT GCCACCAAGA TGTCAGAGTG TGTACTTGGG CAATCAAAAA GAGTGGATTT TTGTGGAAAG GGCTATCATC TTATGTCCTT CCCTCAGTCA GCACCTCATG GTGTAGTCTT CTTGCATGTG ACTTATGTCC CTGCACAGGA GAAGAACTTC ACAACTGCTC CCGCCATTTG CCATGATGGA AAAGCACACT TTCCGCGTGA AGGCGTCTTT GTCTCAAATG GCACACACTG GTTCGTAACA CAAAGGAACT TTTATGAACC ACAAATTATT ACTACTGACA ATACATTTGT GTCTGGGAAC TGTGATGTGG TAATCGGAAT TGTCAACAAC ACAGTCTATG ATCCTTTGCA ACCTGAATTA GACTCATTCA AAGAGGAATT GGATAAATAT TTCAAGAATC ATACATCGCC AGATGTT "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AATGTTCTCT ATGAGAACCA GAAATTAATA GCCAACCAGT TCAATAGTGC TATTGGCAAA ATTCAGGACT CCCTTTCTTC CACAGCGAGC GCACTTGGTA AACTTCAAGA CGTGGTAAAC CAGAATGCAC AAGCTTTGAA TACGCTTGTT AAACAACTTA GTTCGAATTT TGGTGCAATC TCTAGTGTTT TAAATGATAT ACTTTCACGT CTTGAC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["ACTAATATGA AATTCCTTGT GTTCTTAGGA ATCATCACTA CTGTAGCAGC ATTTCACCAA GAATGTAGCT TACAGTCATG TACTCAACAT CAGCCATACG TAGTTGATGA TCCCTGTCCT ATTCATTTCT ATTCTAAATG GTATATTAGG GTTGGAGCTA GAAAATCAGC ACCGTTAATA GAATTGTGCG TGGATGAAGC TGGGTCTAAA TCACCCATTC AATACATCGA TATCGGTAAT TATACAGTTT CCTGCTTACC TTTTACAATT AATTGCCAAG AACCTAAATT GGGTAGTCTT GTCGTTCGTT GTTCGTTCTA TGAAGACTTT TTGGAGTATC ATGACGTTCG TGTGGTATTA GATTTTATCT AA "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["GTTCAGCCTA CCGAATCTAT TGTTAGATTT CCTAATATTA CCAACTTGTG CCCCTTTGGT GAAGTTTTTA ACGCCACCAG ATTTGCATCT GTGTATGCCT GGAACAGGAA GAGAATTAGC AATTGTGTTG CCGACTATTC TGTACTATAT AATTCCGCAT CATTTTCCAC ATTCAAGTGC TATGGAGTGT CCCCTACTAA ATTGAATGAC CTGTGTTTTA CTAATGTCTA CGCAGACTCA TTTGTAATCA GGGGTGACGA AGTCAGACAA ATTGCTCCAG GGCAAACTGG AAAGATAGCT GACTATAATT ATAAGTTGCC GGATGACTTT ACCGGCTGCG TTATAGCTTG GAATTCTAAC AATCTCGATT CCAAAGTCGG TGGTAATTAT AACTATCGCT ATAGGTTATT TAGGAAATCT AATCTCAAAC CTTTTGAGAG AGACATTTCA ACTGAAATCT ATCAAGCCGG AAGTAAACCC TGTAATGGTG TTGAAGGTTT CAATTGTTAC TTTCCTTTAC AATCATATGG CTTCCAACCC ACTAATGGTG TAGGTTACCA ACCATACAGA GTAGTAGTAC TTTCATTTGA ACTTCTACAT GCACCGGCAA CTGTTTGTGG CCCTAAGAAA TCTACTAACT TGGTTAAAAA TAAGTGCGTC AACTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["GTCCAACCAA CAGAATCTAT TGTTAGATTT CCTAATATTA CAAACTTGTG CCCTTTTGGT GAAGTTTTTA ACGCCACCAG ATTTGCATCT GTTTATGCTT GGAACAGGAA GAGAATCAGT AACTGTGTTG CTGATTATTC GGTCCTATAC AATTCCGCAT CATTTTCCAC TTTTAAGTGT TATGGAGTGT CTCCTACTAA ATTAAATGAT CTCTGCTTCA CAAATGTCTA TGCAGATTCA TTTGTAATTA GAGGTGATGA AGTCAGACAA ATCGCTCCAG GGCAAACTGG AAAGATTGCT GATTATAACT ATAAATTACC AGATGATTTC ACAGGCTGCG TTATAGCTTG GAATTCTAAC AATCTTGATT CTAAGGTTGG TGGTAATTAT AATTACCGGT ATAGATTGTT TAGAAAGTCT AATCTCAAAC CTTTCGAGAG AGATATTTCA ACGGAAATCT ACCAAGCCGG TAGCAAACCT TGTAATGGAG TTGAAGGTTT TAACTGTTAC TTTCCTTTAC AATCATATGG TTTCCAACCC ACTAACGGAG TCGGTTACCA GCCATACAGA GTAGTAGTCC TTTCTTTTGA ACTTCTACAT GCACCAGCAA CCGTTTGTGG ACCTAAAAAG TCTACTAATT TGGTTAAAAA CAAATGTGTC AATTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["GTCCAGCCTA CAGAATCTAT AGTTAGATTT CCAAATATAA CAAATTTGTG CCCATTTGGT GAAGTTTTCA ATGCTACCAG ATTTGCATCC GTTTACGCCT GGAACAGGAA GAGAATAAGT AACTGTGTTG CGGACTACTC AGTCCTATAT AATTCCGCAT CATTTTCCAC TTTTAAGTGT TATGGAGTCT CTCCCACTAA GTTAAACGAT CTTTGCTTCA CTAATGTCTA CGCTGATTCA TTTGTAATTA GAGGTGATGA AGTGAGACAG ATCGCTCCCG GGCAAACTGG CAAAATTGCA GACTACAATT ATAAATTACC AGATGATTTC ACAGGCTGCG TTATAGCATG GAATTCTAAT AATCTTGATT CTAAAGTTGG CGGTAACTAT AATTATCGTT ACAGGTTGTT TAGAAAGTCT AATCTGAAGC CCTTTGAAAG GGACATCTCT ACTGAAATCT ATCAGGCCGG TAGCAAGCCA TGCAACGGAG TGGAAGGTTT CAATTGCTAT TTCCCTTTGC AATCGTATGG TTTCCAACCC ACTAATGGTG TTGGGTATCA ACCTTACAGA GTAGTTGTAC TCTCTTTTGA GCTTCTCCAC GCACCAGCAA CTGTCTGTGG ACCAAAGAAA TCAACTAATT TGGTAAAGAA TAAATGCGTC AATTTC"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["GTCCAACCAA CAGAGTCTAT AGTCAGATTT CCTAATATTA CAAACTTGTG CCCTTTTGGC GAAGTTTTCA ACGCCACAAG ATTCGCATCT GTTTATGCTT GGAACAGGAA GAGAATCAGC AACTGTGTTG CTGACTATTC TGTCCTATAT AATTCCGCAT CATTCTCCAC TTTCAAGTGT TATGGAGTCT CTCCTACTAA GTTAAATGAT CTTTGCTTCA CCAATGTGTA TGCAGACTCA TTTGTTATTA GGGGGGATGA GGTTAGACAA ATCGCTCCAG GGCAAACTGG AAAGATCGCG GATTATAACT ATAAATTACC AGATGATTTT ACTGGCTGCG TGATAGCTTG GAATTCTAAC AATCTTGACT CTAAGGTTGG TGGTAATTAT AACTATCGGT ATAGATTGTT TAGGAAGTCT AATCTCAAAC CTTTCGAGAG AGATATTTCT ACTGAAATCT ACCAGGCCGG TAGCAAACCT TGTAACGGGG TTGAAGGATT TAATTGTTAT TTCCCTTTAC AGTCATATGG GTTCCAACCC ACTAATGGTG TTGGTTACCA ACCTTACAGA GTCGTCGTAC TTTCTTTTGA ACTTCTACAT GCACCAGCAA CTGTGTGTGG ACCTAAAAAA TCCACTAATT TGGTTAAAAA CAAATGTGTC AATTTC"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["ACTCATGCAG ACCACACAAG GCAGATGGGC TATATAAACG TTTTCGCTTT TCCTTTTACG ATATATAGCC TACTCTTGTG CAGAATGAAT TCTCGTAACT ACATAGCACA GGTAGATGTG GTTAACTTTA ATCTCACATA GCAATCTTTG ATCAGTGTGT AACACTAGGG AGGGCTTGAA AGAGCCACCA CATTTTCACC GAGGCCTCTC GGAGTACGAT CGAGTGTACA GTGAACAATG CTGGGAAGAG CGGCCTATAT GGAAGAGCCC TAATGTGTTA AATTAATTTT GGTGGTGCTA TCCCCATGTG ATTTTAATAG TTTCTTGGGA "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AACTTCAACG GTTTGACAGG CACAGGTGTC CTTACTGAGT CTAACAAAAA GTTCCTTCCT TTCCAACAAT TCGGCAGAGA CATTGCTGAT ACCACTGATG CTGTCCGTGA TCCCCAGACA CTTGAGATTC TCGACATAAC GCCATGTTCT TTCGGTGGTG TCAGTGTTAT AACCCCCGGA ACAAATACTT CTAACCAAGT TGCTGTTCTT TATCAGGGTG TTAACTGCAC AGAAGTCCCT GTTGCCATAC ATGCAGATCA ACTTACTCCA ACTTGGCGTG TTTATTCGAC CGGTTCTAAC GTTTTTCAGA CGCGTGCCGG GTGTTTAATA GGGGCTGAGC ATGTCAACAA TTCATATGAG TGTGACATTC CCATTGGTGC CGGTATTTGC GCGAGTTATC AGACTCAGAC TAATTCTCGT CGGCGGGCTC GTAGCGTAGC TAGCCAATCC ATCATCGCCT ACACTATGTC ACTAGGTGCA GAGAATTCCG TTGCTTACTC TAACAACTCT ATTGCGATAC CCACAAACTT CACTATTAGT GTTACCACAG AAATTCTACC AGTGTCAATG ACCAAGACAT CCGTAGACTG TACAATGTAC ATTTGTGGTG ACTCAACTGA GTGCAGCAAT CTTTTGTTGC AATACGGCAG TTTTTGTACG CAGTTAAACC GAGCTTTAAC GGGAATCGCT GTTGAGCAAG ACAAAAACAC GCAAGAAGTT TTTGCACAAG TGAAACAAAT C "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["ACCAATTAAA TATTATATTA GTTCTTTTGT TTAGAGCTGT AATTTTAGCC"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AGGGTCCAGC CAACAGAATC TATTGTCAGA TTTCCAAATA TTACAAACTT ATGCCCGTTC GGTGAAGTTT TTAACGCCAC CAGATTTGCA TCTGTTTACG CTTGGAACAG GAAGAGAATA AGCAACTGTG TTGCAGATTA TTCTGTTCTA TATAATTCAG CATCATTCTC AACTTTTAAG TGTTATGGTG TGTCTCCTAC TAAATTGAAT GATCTCTGCT TTACTAATGT CTACGCAGAT TCATTTGTAA TTAGAGGTGA TGAAGTCAGA CAAATCGCTC CAGGACAAAC AGGGAMGATA GCTGATTATA ACTATAAATT ACCTGATGAT TTCACCGGCT GCGTTATAGC TTGGAATTCT AACAATCTTG ATTCTAAGGT TGGTGGTAAT TATAATTATC TATATAGATT GTTTAGGAAG TCTAATCTCA AACCATTTGA GAGAGATATT TCAACTGAAA TCTATCAAGC CGGTAGTACA CCTTGTAACG GTGTTAAAGG TTTCAATTGT TACTTTCCTT TACAATCTTA TGGTTTTCAA CCCACTTATG GTGTTGGCTA TCAGCCATAC AGAGTAGTAG TACTTTCTTT CGAACTTCTA CACGCACCAG CTACTGTCTG TGGACCTAAA AAATCTACGA ATTTGGTTAA AAACAAATGT GTGAATTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AGAGTCCAGC CAACAGAATC TATTGTTAGA TTTCCTAATA TCACAAACTT GTGCCCTTTT GGTGAAGTTT TTAATGCGAC TAGATTTGCA TCCGTTTATG CCTGGAATAG GAAGAGAATT AGTAACTGTG TTGCTGATTA TTCTGTCCTA TACAATTCCG CATCATTTTC CACTTTCAAG TGTTATGGAG TGTCTCCTAC TAAATTAAAT GATCTCTGCT TTACTAATGT CTATGCAGAT TCATTTGTTA TTAGAGGTGA TGAAGTCAGA CAAATCGCTC CAGGGCAAAC TGGAAMGATT GCTGATTATA ATTATAAGTT GCCAGATGAC TTTACGGGTT GTGTTATTGC TTGGAATTCA AATAATCTTG ATTCTAAGGT TGGTGGTAAT TATAATTACC TTTATAGATT GTTTAGGAAG TCTAACCTCA AGCCTTTCGA GAGAGATATT TCAACTGAAA TCTATCAAGC TGGGAGCACA CCTTGTAATG GTGTGAAAGG TTTTAATTGT TACTTTCCTT TGCAATCATA TGGTTTCCAA CCCACTTATG GTGTTGGCTA CCAGCCGTAC AGAGTAGTAG TACTTTCTTT TGAGCTTCTA CATGCACCAG CAACTGTTTG CGGACCGAAA AAGTCGACTA ACTTGGTCAA AAACAAATGT GTCAACTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AGAGTTCAGC CAACAGAATC GATTGTGAGG TTTCCTAATA TAACAAACTT GTGCCCTTTT GGTGAAGTTT TTAACGCCAC CAGATTTGCA TCTGTTTATG CGTGGAATAG GAAGAGAATC AGCAACTGTG TTGCTGACTA TTCTGTACTA TATAATTCCG CTTCATTCTC CACTTTCAAG TGTTATGGTG TCTCGCCTAC TAAATTAAAC GACCTTTGCT TTACTAATGT CTATGCAGAT TCATTTGTTA TTAGAGGTGA TGAAGTTAGA CAGATCGCTC CAGGTCAAAC TGGAAMGATT GCTGACTATA ACTATAAATT GCCAGATGAC TTTACAGGCT GTGTTATAGC ATGGAACTCT AACAATCTTG ATTCTAAGGT TGGTGGGAAT TATAATTACC TGTATAGGTT ATTCAGGAAA TCGAATCTCA AGCCTTTTGA GAGAGATATA TCAACTGAAA TATATCAGGC GGGAAGTACA CCTTGTAACG GTGTTAAAGG TTTCAATTGT TACTTTCCGT TACAATCATA TGGTTTCCAA CCCACTTATG GGGTTGGGTA CCAACCATAC AGAGTGGTAG TACTCTCGTT TGAACTACTA CATGCACCAG CCACTGTGTG TGGGCCGAAA AAATCTACCA ATTTAGTTAA AAATAAATGT GTCAATTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AGAGTGCAAC CAACAGAATC TATTGTTAGA TTCCCGAACA TTACAAACTT GTGCCCCTTT GGCGAGGTAT TCAACGCCAC CAGGTTCGCA TCCGTTTATG CTTGGAACAG GAAGAGGATC AGTAACTGTG TTGCTGATTA CTCGGTCCTA TATAATTCCG CATCGTTCTC CACTTTTAAG TGTTACGGAG TATCTCCTAC GAAATTAAAT GACCTCTGCT TCACCAATGT GTATGCGGAC TCATTTGTGA TTAGAGGTGA TGAAGTCAGA CAGATTGCTC CAGGGCAAAC TGGAAMGATA GCTGATTACA ATTATAAATT ACCTGACGAC TTCACAGGCT GTGTCATAGC TTGGAACTCG AACAATCTTG ATTCCAAGGT GGGTGGAAAT TACAATTATC TGTACAGATT ATTTAGGAAG TCTAATCTCA AACCTTTTGA GAGAGACATT TCTACAGAAA TATATCAGGC GGGCAGCACA CCATGCAACG GAGTCAAAGG TTTTAATTGT TACTTTCCTT TGCAATCGTA CGGTTTTCAG CCCACTTATG GCGTTGGTTA CCAACCATAT AGAGTAGTAG TTCTTTCCTT TGAGCTTCTT CATGCGCCGG CAACGGTGTG TGGCCCAAAA AAGTCAACGA ATTTGGTCAA AAACAAATGC GTGAACTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AGAGTCCAAC CAACAGAATC TATTGTTAGA TTTCCTAATA TTACAAACTT ATGCCCTTTT GGTGAAGTTT TTAACGCCAC CAGATTTGCT TCTGTTTATG CTTGGAACAG GAAGAGAATC AGCAACTGTG TTGCTGATTA TTCTGTCCTA TATAATTCTG CATCATTTTC CACTTTTAAG TGTTATGGAG TGTCTCCTAC TAAATTAAAT GATCTTTGCT TTACTAATGT CTATGCAGAT TCATTTGTAA TTAGAGGCGA TGAAGTCAGG CAAATCGCTC CAGGGCAAAC TGGAAMGATT GCTGATTATA ATTATAAGTT ACCAGATGAT TTTACAGGCT GCGTTATAGC TTGGAATTCT AATAATCTTG ATTCTAAGGT TGGTGGTAAT TATAACTACC TGTATAGATT GTTTAGGAAG TCTAACCTCA AACCTTTTGA AAGAGATATT TCAACTGAAA TCTATCAGGC CGGTAGCACA CCTTGTAATG GTGTCAAAGG GTTTAATTGT TATTTTCCTT TACAATCATA TGGTTTCCAA CCGACGTATG GTGTTGGATA CCAACCATAT AGAGTAGTAG TACTTTCTTT TGAACTTCTA CATGCACCAG CAACTGTTTG TGGACCAAAA AAGTCTACTA ATTTGGTTAA AAACAAATGT GTCAATTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["AGGGTGCAAC CAACTGAATC AATTGTTAGA TTTCCTAATA TTACAAACTT ATGCCCATTT GGTGAAGTTT TTAACGCCAC CAGATTCGCA TCTGTTTATG CTTGGAACAG GAAGAGAATC AGCAACTGTG TTGCTGATTA TTCTGTCCTA TATAATTCCG CATCATTTTC CACTTTTAAG TGTTATGGAG TGTCTCCTAC TAAATTAAAT GATCTCTGCT TTACTAATGT CTATGCTGAT TCATTTGTAA TTAGAGGTGA TGAAGTCAGA CAAATCGCTC CAGGGCAAAC TGGAAMGATT GCTGACTATA ATTATAAATT ACCAGATGAT TTTACAGGCT GCGTTATAGC TTGGAATTCT AACAATCTTG ATTCTAAGGT TGGAGGTAAT TATAATTACC TCTACAGATT GTTCAGGAAG TCTAACCTCA AACCTTTTGA GAGAGATATT TCGACCGAGA TCTATCAGGC TGGTAGCACA CCTTGTAACG GGGTTAAAGG TTTTAATTGT TACTTTCCTT TACAATCATA TGGTTTCCAA CCCACTTACG GCGTTGGTTA CCAACCATAT AGAGTTGTAG TACTTTCTTT TGAACTCCTA CATGCACCAG CAACTGTTTG TGGACCTAAA AAGTCTACTA ATTTGGTCAA AAACAAATGT GTAAATTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")     

j=j+1
txt=["AGAGTCCAAC CGACAGAATC TATTGTTAGA TTTCCCAATA TTACAAACTT ATGCCCGTTT GGTGAAGTTT TCAATGCCAC CAGATTCGCA TCTGTTTATG CTTGGAACAG GAAGAGAATC AGCAACTGTG TTGCTGATTA TTCAGTCCTA TATAACTCCG CATCATTTTC CACTTTTAAG TGCTATGGAG TGTCTCCGAC TAAATTAAAT GATCTCTGCT TCACTAATGT CTATGCAGAT TCATTTGTAA TTAGAGGTGA TGAAGTCAGA CAAATCGCTC CAGGTCAAAC TGGAAMGATT GCTGATTATA ACTACAAATT ACCAGATGAT TTTACAGGCT GCGTTATAGC TTGGAATTCA AACAATCTTG ACTCAAAGGT TGGTGGCAAT TATAATTACC TGTATAGGTT GTTTAGGAAG TCCAATCTCA AACCCTTTGA AAGAGACATA TCGACTGAAA TCTATCAGGC CGGTAGCACA CCTTGTAATG GTGTTAAAGG TTTTAATTGT TACTTTCCTT TACAATCATA TGGTTTCCAA CCCACTTATG GTGTTGGTTA CCAACCATAC AGAGTAGTAG TACTCTCATT TGAACTTCTA CACGCACCAG CAACTGTTTG TGGACCTAAA AAGTCAACGA ATTTGGTTAA AAATAAATGT GTCAATTTC "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["ATGGAGAGCC TAGTTCCTGG TTTCAACGAA AAAACACACG TCCAACTCAG TTTGCCTGTG TTACAGGTTC GCGACGTGCT CGTTCGTGGT TTTGGAGACT CCGTGGAGGA GGTCTTATCA GAGGCACGTC AGCACCTTAA AGATGGAACT TGTGGGTTAG TAGAAGTGGA GAAGGGCGTT TTGCCTCAAC TTGAACAGCC CTACGTGTTT ATCAAACGTT CCGATGCTCG GACTGCACCT CATGGTCATG TTATGGTTGA GCTCGTAGCA GAACTAGAAG GAATTCAGTA CGGTCGTAGC GGTGAAACAC TTGGGGTCCT TGTCCCTCAT GTGGGCGAAA TACCAGTAGC TTACCGCAAG GTTCTTCTTC GTAAAAACGG TAACAAAGGA GCTGGAGGCC ATAGTTATGG GGCCGATCTC AAATCTTTTG ATTTAGGCGA CGAGCTTGGC ACCGATCCTT ACGAAGACTT CCAAGAAAAC TGGAATACTA AGCACAGCAG TGGTGTTACA CGTGAACTTA TGCGCGAGCT TAACGGAGGG"]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["ACAGATTTTT CCAGAGTTAG TGCTAAACCA CCGCCTGGAG ATCAATTCAA ACACCTCATA CCACTTATGT ACAAAGGACT TCCCTGGAAT GTAGTGCGTA TAAAGATAGT ACAAATGTTA AGTGACACAC TTAAAAATCT CTCTGACAGA GTCGTATTTG TCTTATGGGC ACATGGCTTT GAGTTGACAT CTATGAAGTA TTTTGTGAAA ATAGGACCTG AGCGCACCTG TTGTCTATGT GATAGACGTG CCACATGCTT TTCCACTGCT TCGGACACTT ATGCCTGTTG GCATCATTCT ATTGGATTTG ATTACGTCTA TAATCCTTTT ATGATTGATG TTCAACAATG GGGTTTTACA GGTAACCTAC AAAGTAACCA TGATCTGTAT TGCCAAGTCC ATGGTAATGC GCATGTAGCT AGTTGTGATG CAATCATGAC TAGGTGTCTG GCTGTCCACG AGTGCTTTGT TAAGCGTGTT GACTGGACTA TTGAATATCC AATAATAGGT GATGAACTGA AGATTAATGC GGCTTGTAGA AAAGTTCAGC ATATGGTTGT TAAAGCTGCA TTATTAGCAG ACAAATTCCC AGTTCTTCAC GACATTGGTA ACCCTAAAGC TATAAAGTGC GTACCTCAAG CTGATGTGGA ATGGAAGTTT TATGATGCAC AGCCTTGTAG TGACAAAGCT TATAAAATAG AAGAATTATT CTATTCTTAT GCCACTCATT CTGATAAATT CACAGATGGT GTATGCCTAT TTTGGAATTG CAATGTCGAT AGATATCCTG CTAACTCCAT TGTTTGTAGA TTTGACACTA GAGTGCTATC TAACCTTAAC TTGCCTGGTT GTGATGGTGG CAGTTTGTAT GTAAATAAAC ATGCATTCCA CACACCAGCT TTTGATAAAA GTGCTTTTGT TAATTTAAAG CAATTGCCAT TTTTCTATTA CTCTGATAGT CCATGTGAGT CTCATGGAAA ACAAGTAGTG TCAGATATAG ATTATGTACC ACTAAAGTCT GCCACTTGTA TAACACGTTG CAATTTAGGT GGTGCTGTCT GTAGACATCA TGCTAATGAG TACAGATTGT ATCTCGATGC TTATAACATG ATGATCTCAG CTGGCTTTAG CTTGTGGGTT TACAAACAAT TTGATACTTA TAACCTCTGG AACACTTTTA CAAGACTTCA G "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")
j=j+1
txt=["ATGGCAGATT CCAACGGTAC TATTACCGTT GAGGAGCTAA AAAAGCTACT TGAGCAATGG AACCTAGTAA TAGGTTTCCT ATTCCTTACA TGGATATGTC TTCTTCAGTT TGCATACGCG AACAGAAATA GGTTTTTGTA CATAATTAAG TTAATTTTTC TCTGGCTGTT ATGGCCAGTA ACTTTAGCTT GTTTTGTGCT TGCTGCCGTT TACAGAATAA ATTGGATTAC CGGAGGAATT GCTATCGCAA TGGCTTGTCT TGTAGGCTTG ATGTGGCTTA GCTATTTCAT AGCCTCTTTC AGACTGTTTG CGCGGACTCG TTCGATGTGG TCATTCAATC CAGAGACTAA TATTCTTCTC AACGTGCCAC TTCATGGCAC TATTCTGACG AGACCGCTTC TAGAAAGTGA ACTCGTCATT GGAGCGGTGA TCCTTCGCGG ACACCTTCGG ATTGCTGGAC ACCATCTTGG GCGCTGCGAT ATCAAGGACC TTCCTAAAGA AATCACTGTT GCAACATCAC GCACGCTCTC TTACTACAAA TTGGGAGCTT CGCAACGTGT AGCAGGTGAC TCAGGTTTCG CTGCATACAG CCGCTATAGA ATTGGAAACT ATAAATTAAA CACAGACCAT TCTAGTAGCA GTGACAATAT TGCTTTGCTT GTCCAATAA "]
seq = tokenizer.texts_to_sequences(txt)
padded = pad_sequences(seq, maxlen=max_length)
pred=model.predict(padded)
#print(pred)
predicted=0
if pred>=0.5:
  predicted=1
if predicted==1:
  print(j,": ",pred,"sequance is positive ")
else:
  print(j,": ",pred,"sequance is negative ")


                                                                                                       